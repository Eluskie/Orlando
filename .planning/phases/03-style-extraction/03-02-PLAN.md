---
phase: 03-style-extraction
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/lib/ai/style-extraction.ts
  - src/types/brand.ts
  - src/app/api/chat/route.ts
  - src/app/api/brands/[brandId]/style/route.ts
  - src/lib/ai/mock.ts
autonomous: true

must_haves:
  truths:
    - "AI extracts color palette from reference images"
    - "AI extracts mood/keywords from reference images"
    - "AI extracts typography hints from reference images"
    - "Extraction returns structured JSON matching schema"
    - "Mock mode returns plausible style extraction"
    - "Extracted style is saved to brand database"
  artifacts:
    - path: "src/lib/ai/style-extraction.ts"
      provides: "Zod schema and extraction function"
      exports: ["StyleExtractionSchema", "ExtractedStyle", "extractStyleFromImages"]
    - path: "src/types/brand.ts"
      provides: "Extended BrandStyle with extractedStyle"
      contains: "extractedStyle?"
    - path: "src/app/api/chat/route.ts"
      provides: "Image processing in chat flow with style persistence"
      contains: "type.*image"
    - path: "src/app/api/brands/[brandId]/style/route.ts"
      provides: "Style persistence endpoint"
      exports: ["PATCH"]
  key_links:
    - from: "src/app/api/chat/route.ts"
      to: "src/lib/ai/style-extraction.ts"
      via: "import extractStyleFromImages"
      pattern: "import.*style-extraction"
    - from: "src/lib/ai/style-extraction.ts"
      to: "@ai-sdk/google"
      via: "generateText with Output.object"
      pattern: "Output\\.object"
    - from: "src/app/api/chat/route.ts"
      to: "/api/brands/[brandId]/style"
      via: "fetch PATCH to persist style"
      pattern: "fetch.*api/brands.*style"
---

<objective>
Implement AI-powered style extraction with Zod schema and persistence

Purpose: The core of Phase 3 - analyze reference images using Gemini Vision and extract structured style data (colors, mood, typography, visual characteristics) into a validated JSON format, then persist it to the brand database.

Output:
- StyleExtractionSchema (Zod) for type-safe extraction
- ExtractedStyle type for TypeScript usage
- extractStyleFromImages function using Gemini 2.5 Flash
- Extended BrandStyle type with extractedStyle field
- Style persistence API endpoint
- Updated chat API to detect images, trigger extraction, and save to brand
- Mock mode support for development
</objective>

<execution_context>
@C:\Users\gerar\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gerar\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-style-extraction/03-RESEARCH.md
@.planning/phases/03-style-extraction/03-01-SUMMARY.md

@src/app/api/chat/route.ts
@src/lib/ai/mock.ts
@src/types/brand.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create style extraction schema, function, and persistence API</name>
  <files>
    src/lib/ai/style-extraction.ts
    src/types/brand.ts
    src/app/api/brands/[brandId]/style/route.ts
    package.json
  </files>
  <action>
1. Ensure zod is installed (should be from AI SDK, but verify):
   ```bash
   npm install zod
   ```

2. Create src/lib/ai/style-extraction.ts:

```typescript
import { generateText, Output } from 'ai';
import { google } from '@ai-sdk/google';
import { z } from 'zod';

// Zod schema for style extraction - matches RESEARCH.md specification
export const StyleExtractionSchema = z.object({
  colors: z.object({
    primary: z.string().describe('Main dominant color as hex code (#RRGGBB)'),
    secondary: z.string().describe('Secondary color as hex code'),
    accent: z.string().describe('Accent/highlight color as hex code'),
    neutral: z.string().describe('Background/neutral color as hex code'),
  }),
  typography: z.object({
    style: z.enum(['serif', 'sans-serif', 'display', 'handwritten', 'monospace'])
      .describe('Overall typography style that would match this visual'),
    weight: z.enum(['light', 'regular', 'medium', 'bold', 'heavy'])
      .describe('Dominant font weight impression'),
    mood: z.string().describe('Typography mood: modern, classic, playful, elegant, etc.'),
  }),
  mood: z.object({
    primary: z.string().describe('Primary mood/feeling: energetic, calm, luxurious, minimal, etc.'),
    keywords: z.array(z.string()).min(3).max(5).describe('3-5 descriptive style keywords'),
    tone: z.enum(['warm', 'cool', 'neutral']).describe('Overall color temperature'),
  }),
  visualStyle: z.object({
    complexity: z.enum(['minimal', 'moderate', 'detailed', 'ornate']),
    contrast: z.enum(['low', 'medium', 'high']),
    texture: z.string().describe('Texture quality: smooth, grainy, organic, geometric, etc.'),
  }),
  confidence: z.number().min(0).max(1).describe('Extraction confidence 0-1'),
});

export type ExtractedStyle = z.infer<typeof StyleExtractionSchema>;

const EXTRACTION_PROMPT = `Analyze this reference image(s) and extract the visual style characteristics.

Return a JSON object with:
1. colors: Extract dominant colors as precise hex codes (#RRGGBB format)
   - primary: The main brand/dominant color
   - secondary: A supporting color
   - accent: A highlight or call-to-action color
   - neutral: Background or text-suitable color

2. typography: Infer the typography style that would complement this visual
   - style: serif, sans-serif, display, handwritten, or monospace
   - weight: light, regular, medium, bold, or heavy
   - mood: A word describing the typography feel

3. mood: The emotional and stylistic impression
   - primary: Main mood descriptor
   - keywords: 3-5 words capturing the brand essence
   - tone: warm, cool, or neutral

4. visualStyle: Technical visual characteristics
   - complexity: minimal, moderate, detailed, or ornate
   - contrast: low, medium, or high
   - texture: A word describing the texture quality

5. confidence: Your confidence in this extraction (0-1)

Be specific and precise. When analyzing multiple images, find common threads.`;

/**
 * Extract style from one or more reference images
 * Uses Gemini 2.5 Flash for vision analysis with structured output
 */
export async function extractStyleFromImages(
  imageUrls: string[]
): Promise<ExtractedStyle> {
  // Build content array with all images
  const imageContent = imageUrls.map(url => ({
    type: 'image' as const,
    image: url,
  }));

  const { output } = await generateText({
    model: google('gemini-2.5-flash'),
    output: Output.object({ schema: StyleExtractionSchema }),
    messages: [
      {
        role: 'user',
        content: [
          ...imageContent,
          { type: 'text', text: EXTRACTION_PROMPT },
        ],
      },
    ],
  });

  return output;
}

/**
 * Mock style extraction for development
 */
export function mockExtractStyle(): ExtractedStyle {
  const palettes = [
    { primary: '#2563EB', secondary: '#1E40AF', accent: '#F59E0B', neutral: '#F3F4F6' },
    { primary: '#059669', secondary: '#047857', accent: '#EC4899', neutral: '#ECFDF5' },
    { primary: '#7C3AED', secondary: '#5B21B6', accent: '#10B981', neutral: '#F5F3FF' },
  ];
  const moods = ['modern', 'playful', 'elegant', 'bold', 'minimal'];
  const keywords = [
    ['clean', 'professional', 'trustworthy', 'innovative'],
    ['vibrant', 'energetic', 'youthful', 'dynamic'],
    ['luxurious', 'sophisticated', 'premium', 'refined'],
  ];

  const idx = Math.floor(Math.random() * 3);

  return {
    colors: palettes[idx],
    typography: {
      style: 'sans-serif',
      weight: 'medium',
      mood: moods[Math.floor(Math.random() * moods.length)],
    },
    mood: {
      primary: moods[Math.floor(Math.random() * moods.length)],
      keywords: keywords[idx],
      tone: ['warm', 'cool', 'neutral'][Math.floor(Math.random() * 3)] as 'warm' | 'cool' | 'neutral',
    },
    visualStyle: {
      complexity: 'moderate',
      contrast: 'medium',
      texture: 'smooth',
    },
    confidence: 0.85 + Math.random() * 0.1,
  };
}
```

3. Update src/types/brand.ts to include extractedStyle:

```typescript
export interface ExtractedStyleData {
  colors: {
    primary: string;
    secondary: string;
    accent: string;
    neutral: string;
  };
  typography: {
    style: 'serif' | 'sans-serif' | 'display' | 'handwritten' | 'monospace';
    weight: 'light' | 'regular' | 'medium' | 'bold' | 'heavy';
    mood: string;
  };
  mood: {
    primary: string;
    keywords: string[];
    tone: 'warm' | 'cool' | 'neutral';
  };
  visualStyle: {
    complexity: 'minimal' | 'moderate' | 'detailed' | 'ornate';
    contrast: 'low' | 'medium' | 'high';
    texture: string;
  };
  confidence: number;
  extractedAt: string;
  sourceImages: string[];
}

export interface BrandStyle {
  primaryColor?: string;
  secondaryColor?: string;
  accentColor?: string;
  fontFamily?: string;
  headingFont?: string;
  tone?: string;
  keywords?: string[];
  referenceImages?: string[];
  extractedStyle?: ExtractedStyleData;
}
```

4. Create src/app/api/brands/[brandId]/style/route.ts for style persistence:

```typescript
import { NextResponse } from 'next/server';
import { db } from '@/lib/db';
import { brands } from '@/lib/db/schema';
import { eq } from 'drizzle-orm';
import type { ExtractedStyleData } from '@/types/brand';

interface StyleUpdateBody {
  extractedStyle: ExtractedStyleData;
  referenceImages: string[];
}

export async function PATCH(
  request: Request,
  { params }: { params: Promise<{ brandId: string }> }
) {
  try {
    const { brandId } = await params;
    const body: StyleUpdateBody = await request.json();

    // Get current brand
    const [brand] = await db
      .select()
      .from(brands)
      .where(eq(brands.id, brandId));

    if (!brand) {
      return NextResponse.json({ error: 'Brand not found' }, { status: 404 });
    }

    // Merge with existing style
    const updatedStyle = {
      ...brand.style,
      extractedStyle: {
        ...body.extractedStyle,
        extractedAt: new Date().toISOString(),
        sourceImages: body.referenceImages,
      },
      referenceImages: [
        ...(brand.style?.referenceImages || []),
        ...body.referenceImages,
      ],
      // Also populate top-level colors from extraction
      primaryColor: body.extractedStyle.colors.primary,
      secondaryColor: body.extractedStyle.colors.secondary,
      accentColor: body.extractedStyle.colors.accent,
      keywords: body.extractedStyle.mood.keywords,
      tone: body.extractedStyle.mood.primary,
    };

    // Update brand
    await db
      .update(brands)
      .set({
        style: updatedStyle,
        updatedAt: new Date(),
      })
      .where(eq(brands.id, brandId));

    return NextResponse.json({ success: true, style: updatedStyle });
  } catch (error) {
    console.error('Style update error:', error);
    return NextResponse.json(
      { error: 'Failed to update style' },
      { status: 500 }
    );
  }
}
```
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - src/lib/ai/style-extraction.ts exists with exports
    - src/types/brand.ts includes ExtractedStyleData and updated BrandStyle
    - src/app/api/brands/[brandId]/style/route.ts exists with PATCH export
  </verify>
  <done>
    Style extraction schema defined with Zod. extractStyleFromImages uses Gemini 2.5 Flash with Output.object(). mockExtractStyle provides dev fallback. BrandStyle type extended. Style persistence API created.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate style extraction into chat API with persistence</name>
  <files>
    src/app/api/chat/route.ts
    src/lib/ai/mock.ts
  </files>
  <action>
1. Update src/app/api/chat/route.ts to:

a) Import style extraction:
```typescript
import { extractStyleFromImages, mockExtractStyle, type ExtractedStyle } from '@/lib/ai/style-extraction';
```

b) Detect image parts in messages. Add helper function:
```typescript
function extractImageUrls(messages: UIMessage[]): string[] {
  const urls: string[] = [];
  for (const msg of messages) {
    if (msg.parts) {
      for (const part of msg.parts) {
        if (part.type === 'file' && part.mediaType?.startsWith('image/')) {
          urls.push(part.url);
        }
      }
    }
  }
  return urls;
}
```

c) Update the request body parsing to accept brandId:
```typescript
const { messages, brandId } = await request.json();
```

d) After getting messages from request, check for images and extract style:
```typescript
const imageUrls = extractImageUrls(messages);
let extractedStyle: ExtractedStyle | null = null;

if (imageUrls.length > 0) {
  // Extract style from images
  extractedStyle = isMockMode()
    ? mockExtractStyle()
    : await extractStyleFromImages(imageUrls);
}
```

e) **CRITICAL: Persist extracted style to brand database if brandId is provided:**
```typescript
// After style extraction, save to brand
if (extractedStyle && brandId) {
  try {
    const stylePayload = {
      extractedStyle: {
        ...extractedStyle,
        extractedAt: new Date().toISOString(),
        sourceImages: imageUrls,
      },
      referenceImages: imageUrls,
    };

    // Call the style persistence endpoint using internal fetch
    const baseUrl = process.env.NEXT_PUBLIC_APP_URL ||
                    process.env.VERCEL_URL ? `https://${process.env.VERCEL_URL}` :
                    'http://localhost:3000';
    await fetch(`${baseUrl}/api/brands/${brandId}/style`, {
      method: 'PATCH',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(stylePayload),
    });
  } catch (error) {
    console.error('Failed to persist extracted style:', error);
    // Don't fail the chat request, just log the error
  }
}
```

f) Include extraction in system prompt context if available:
```typescript
const systemWithContext = extractedStyle
  ? `${SYSTEM_PROMPT}\n\n[EXTRACTED STYLE]\n${JSON.stringify(extractedStyle, null, 2)}\n\nIncorporate this extracted style into your response. Present the colors, mood, and typography findings to the user.`
  : SYSTEM_PROMPT;
```

g) Pass systemWithContext to streamText and mock response

2. Update src/lib/ai/mock.ts to handle style extraction context:

a) Add pattern to detect when images were uploaded:
```typescript
// In getMockResponse function, add case for style extraction
if (userMessage.toLowerCase().includes('reference') ||
    userMessage.toLowerCase().includes('analyze') ||
    userMessage.toLowerCase().includes('style')) {
  return {
    content: `I've analyzed your reference images and extracted the following style characteristics:

**Color Palette:**
- Primary: A strong blue (#2563EB)
- Secondary: Deep blue (#1E40AF)
- Accent: Warm amber (#F59E0B)
- Neutral: Light gray (#F3F4F6)

**Typography:** Sans-serif, medium weight with a modern feel

**Mood:** Clean, professional, and innovative

**Visual Style:** Moderate complexity with medium contrast and smooth textures

This style profile has been saved to your brand. You can now generate assets that match this aesthetic!

Would you like to:
1. Generate an illustration using this style
2. Upload additional references to refine the style
3. View your brand's moodboard`,
    metadata: { type: 'style-extraction' },
  };
}
```

3. Update the SYSTEM_PROMPT in src/lib/ai/chat.ts to guide extraction responses:

Add to the system prompt:
```
When users upload reference images, analyze them and provide feedback on:
- The colors you detected (show hex codes)
- The mood and feeling
- Typography that would complement the style
- Overall visual characteristics

Always acknowledge the extracted style and offer next steps.
```
  </action>
  <verify>
    - `npm run build` passes
    - Chat API handles messages with image parts
    - Chat API accepts brandId in request body
    - Mock mode returns style extraction response for image uploads
    - Real mode calls extractStyleFromImages when images present
    - Style is saved to brand via PATCH /api/brands/[brandId]/style
  </verify>
  <done>
    Chat API detects image parts, extracts style (real or mock), saves style to brand database via PATCH endpoint, includes extraction context in AI response. System prompt updated to guide extraction feedback.
  </done>
</task>

</tasks>

<verification>
1. Schema check:
   - StyleExtractionSchema validates correct data
   - ExtractedStyle type matches schema inference
   - BrandStyle.extractedStyle optional field present

2. Function check:
   - extractStyleFromImages accepts string[] of URLs
   - Returns Promise<ExtractedStyle>
   - Uses Gemini 2.5 Flash (not deprecated 2.0)

3. API check:
   - PATCH /api/brands/[brandId]/style accepts extractedStyle and referenceImages
   - Updates brand.style in database
   - Returns updated style

4. Integration check:
   - Chat API detects image parts in messages
   - Chat API accepts brandId in request body
   - Calls extraction when images present
   - Mock mode returns plausible style data
   - System prompt includes extraction context

5. Persistence check:
   - Chat API calls PATCH /api/brands/[brandId]/style after extraction
   - Style data includes extractedAt and sourceImages
   - Errors are logged but don't fail chat request

6. Build check:
   - `npm run build` completes without errors
</verification>

<success_criteria>
- StyleExtractionSchema defined with Zod, matches RESEARCH.md spec
- extractStyleFromImages function uses Gemini 2.5 Flash with Output.object()
- mockExtractStyle returns valid random style data
- BrandStyle type extended with extractedStyle field
- Style persistence API at /api/brands/[brandId]/style with PATCH method
- Chat API extracts image URLs from message parts
- Chat API triggers style extraction when images present
- Chat API persists extracted style to brand database
- Mock mode provides style extraction feedback
- TypeScript compilation passes
</success_criteria>

<output>
After completion, create `.planning/phases/03-style-extraction/03-02-SUMMARY.md`
</output>

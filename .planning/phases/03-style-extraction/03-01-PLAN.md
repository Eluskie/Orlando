---
phase: 03-style-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/components/chat/chat-input.tsx
  - src/app/api/upload/route.ts
  - src/lib/storage/blob.ts
  - src/app/(chat)/page.tsx
  - package.json
autonomous: true
user_setup:
  - service: vercel-blob
    why: "Persistent storage for reference images"
    env_vars:
      - name: BLOB_READ_WRITE_TOKEN
        source: "Vercel Dashboard -> Storage -> Create Blob Store -> Token"

must_haves:
  truths:
    - "User can select 1-3 images via file input in chat"
    - "Selected images show as previews before sending"
    - "User can clear selected images before sending"
    - "Images upload to Vercel Blob on send"
    - "Image URLs are passed to chat API with message"
  artifacts:
    - path: "src/components/chat/chat-input.tsx"
      provides: "File input with preview and clear functionality"
      contains: "input type=\"file\""
    - path: "src/app/api/upload/route.ts"
      provides: "Blob upload endpoint"
      exports: ["POST"]
    - path: "src/lib/storage/blob.ts"
      provides: "Blob upload utilities"
      exports: ["uploadReferenceImage"]
    - path: "src/app/(chat)/page.tsx"
      provides: "Wiring between file upload and chat API"
      contains: "fetch.*api/upload"
  key_links:
    - from: "src/components/chat/chat-input.tsx"
      to: "src/app/(chat)/page.tsx"
      via: "onSend callback with files parameter"
      pattern: "onSend.*files"
    - from: "src/app/(chat)/page.tsx"
      to: "/api/upload"
      via: "fetch POST with FormData"
      pattern: "fetch.*api/upload"
    - from: "src/app/(chat)/page.tsx"
      to: "/api/chat"
      via: "image URLs in message parts"
      pattern: "type.*image"
---

<objective>
Enable image upload in chat with Vercel Blob storage

Purpose: Users need to upload reference images as the first step of style extraction. This plan adds file attachment to the existing chat input and stores images persistently in Vercel Blob.

Output:
- Updated chat input with file attachment UI (button, previews, clear)
- Vercel Blob upload API route
- Storage utilities for reference images
- Page component wiring to upload files and pass URLs to chat API
</objective>

<execution_context>
@C:\Users\gerar\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gerar\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-style-extraction/03-RESEARCH.md

@src/components/chat/chat-input.tsx
@src/app/api/chat/route.ts
@src/app/(chat)/page.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Vercel Blob storage infrastructure</name>
  <files>
    src/app/api/upload/route.ts
    src/lib/storage/blob.ts
    package.json
  </files>
  <action>
1. Install @vercel/blob:
   ```bash
   npm install @vercel/blob
   ```

2. Create src/lib/storage/blob.ts with upload utility:
   ```typescript
   import { put } from '@vercel/blob';

   export interface UploadResult {
     url: string;
     pathname: string;
   }

   export async function uploadReferenceImage(
     file: File,
     brandId: string
   ): Promise<UploadResult> {
     const blob = await put(
       `brands/${brandId}/references/${file.name}`,
       file,
       {
         access: 'public',
         addRandomSuffix: true,
       }
     );
     return { url: blob.url, pathname: blob.pathname };
   }
   ```

3. Create src/app/api/upload/route.ts:
   ```typescript
   import { put } from '@vercel/blob';
   import { NextResponse } from 'next/server';

   export async function POST(request: Request) {
     const formData = await request.formData();
     const file = formData.get('file') as File;
     const brandId = formData.get('brandId') as string;

     if (!file) {
       return NextResponse.json({ error: 'No file provided' }, { status: 400 });
     }

     // Use generic path if no brandId (new brand flow)
     const path = brandId
       ? `brands/${brandId}/references/${file.name}`
       : `temp/references/${file.name}`;

     const blob = await put(path, file, {
       access: 'public',
       addRandomSuffix: true,
     });

     return NextResponse.json({
       url: blob.url,
       pathname: blob.pathname,
     });
   }
   ```

Note: BLOB_READ_WRITE_TOKEN env var must be set. The execute workflow will prompt for user setup after automation.
  </action>
  <verify>
    - `npm ls @vercel/blob` shows package installed
    - Files exist at src/app/api/upload/route.ts and src/lib/storage/blob.ts
    - TypeScript compilation: `npx tsc --noEmit` passes
  </verify>
  <done>
    Vercel Blob infrastructure ready. Upload endpoint accepts POST with FormData (file + brandId), returns { url, pathname }.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update ChatInput with file attachment UI</name>
  <files>
    src/components/chat/chat-input.tsx
  </files>
  <action>
Update src/components/chat/chat-input.tsx to:

1. Add state for selected files and previews:
   ```typescript
   const fileInputRef = useRef<HTMLInputElement>(null);
   const [selectedFiles, setSelectedFiles] = useState<File[]>([]);
   const [previews, setPreviews] = useState<string[]>([]);
   ```

2. Add file selection handler (max 3 files, images only):
   ```typescript
   const handleFileSelect = (e: ChangeEvent<HTMLInputElement>) => {
     const files = e.target.files;
     if (!files) return;

     const validFiles = Array.from(files)
       .filter(f => f.type.startsWith('image/'))
       .slice(0, 3);

     setSelectedFiles(validFiles);

     // Generate previews
     validFiles.forEach(file => {
       const reader = new FileReader();
       reader.onload = () => {
         setPreviews(prev => [...prev, reader.result as string]);
       };
       reader.readAsDataURL(file);
     });
   };
   ```

3. Add clear function:
   ```typescript
   const clearFiles = () => {
     setSelectedFiles([]);
     setPreviews([]);
     if (fileInputRef.current) fileInputRef.current.value = '';
   };
   ```

4. Update props interface to accept onSendWithFiles:
   ```typescript
   interface ChatInputProps {
     onSend: (text: string, files?: File[]) => void;
     disabled: boolean;
     onStop: () => void;
   }
   ```

5. Update handleSubmit to pass files and clear after send:
   ```typescript
   const handleSubmit = useCallback(() => {
     const trimmed = input.trim();
     if ((!trimmed && selectedFiles.length === 0) || disabled) return;
     onSend(trimmed || 'Please analyze these reference images.', selectedFiles.length > 0 ? selectedFiles : undefined);
     setInput('');
     clearFiles();
   }, [input, disabled, onSend, selectedFiles]);
   ```

6. Enable the Paperclip button (currently disabled):
   - Add hidden file input with ref
   - Wire Paperclip click to trigger file input
   - Add accept="image/*" and multiple (max 3)

7. Add preview section above input when files selected:
   ```tsx
   {previews.length > 0 && (
     <div className="flex gap-2 mb-3 px-4">
       {previews.map((src, i) => (
         <div key={i} className="relative">
           <img src={src} alt={`Preview ${i + 1}`} className="w-16 h-16 object-cover rounded-lg border" />
         </div>
       ))}
       <button type="button" onClick={clearFiles} className="text-gray-400 hover:text-gray-600">
         <X className="w-4 h-4" />
       </button>
     </div>
   )}
   ```

8. Import X from lucide-react

Keep the existing textarea, send/stop buttons, and Shift+Enter behavior unchanged.
  </action>
  <verify>
    - `npm run build` passes
    - Open http://localhost:3000, click Paperclip icon
    - Can select up to 3 images, see previews
    - Can click X to clear selected images
    - Send button works with images selected
  </verify>
  <done>
    ChatInput has working file attachment: Paperclip opens file picker, previews show selected images (max 3), X clears selection, onSend receives files array.
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire page component to upload files and pass to chat API</name>
  <files>
    src/app/(chat)/page.tsx
  </files>
  <action>
Update src/app/(chat)/page.tsx to handle file uploads when sending messages with images:

1. Update the sendMessage function signature to accept optional files:
   ```typescript
   const sendMessage = useCallback(async (text: string, files?: File[]) => {
   ```

2. Add file upload logic at the start of sendMessage, before creating the user message:
   ```typescript
   // Upload files if provided
   let imageUrls: string[] = [];
   if (files && files.length > 0) {
     const uploadPromises = files.map(async (file) => {
       const formData = new FormData();
       formData.append('file', file);
       // No brandId yet in home page flow

       const response = await fetch('/api/upload', {
         method: 'POST',
         body: formData,
       });

       if (!response.ok) {
         throw new Error('Upload failed');
       }

       const { url } = await response.json();
       return url;
     });

     imageUrls = await Promise.all(uploadPromises);
   }
   ```

3. Update the userMessage to include image parts when files were uploaded:
   ```typescript
   const userMessage: Message = {
     id: crypto.randomUUID(),
     role: "user",
     content: text,
     parts: [
       // Add image parts first
       ...imageUrls.map(url => ({
         type: "file" as const,
         mediaType: "image/jpeg",
         url,
       })),
       // Then text part
       { type: "text", text },
     ],
   };
   ```

4. Ensure the Message interface supports file parts:
   ```typescript
   interface Message {
     id: string;
     role: "user" | "assistant";
     content: string;
     parts?: Array<{ type: string; text?: string; url?: string; mediaType?: string }>;
   }
   ```

5. Add loading state for uploads (optional but good UX):
   ```typescript
   const [isUploading, setIsUploading] = useState(false);
   ```

   Wrap the upload logic:
   ```typescript
   setIsUploading(true);
   try {
     // upload logic
   } finally {
     setIsUploading(false);
   }
   ```

6. Update ChatInput disabled prop to include isUploading:
   ```tsx
   <ChatInput
     onSend={sendMessage}
     disabled={isLoading || isCreatingBrand || isUploading}
     onStop={() => {}}
   />
   ```

This ensures:
- Files selected in ChatInput are uploaded to /api/upload
- Upload returns Vercel Blob URLs
- URLs are included as image parts in the message sent to /api/chat
- Chat API receives messages with image parts for style extraction
  </action>
  <verify>
    - `npm run build` passes
    - Select images in ChatInput, click send
    - Network tab shows POST to /api/upload for each file
    - Network tab shows POST to /api/chat with image parts in messages
    - Console shows no errors
  </verify>
  <done>
    Page component intercepts files from ChatInput, uploads to Vercel Blob, includes image URLs in chat API request as file parts with mediaType.
  </done>
</task>

</tasks>

<verification>
1. Infrastructure check:
   - `npm ls @vercel/blob` shows ^1.x installed
   - Upload route exists and exports POST
   - Blob utility exports uploadReferenceImage

2. UI check (dev server):
   - Paperclip button enabled and clickable
   - File picker accepts images only
   - Preview thumbnails render correctly
   - Clear button removes previews
   - Send passes files to parent callback

3. Wiring check:
   - Page uploads files to /api/upload before sending message
   - Chat API receives messages with image parts
   - Image URLs are Vercel Blob URLs (not local)

4. TypeScript check:
   - `npx tsc --noEmit` passes with no errors
</verification>

<success_criteria>
- User can click Paperclip to open file picker
- User can select 1-3 images (other files rejected)
- Previews display as 64x64 thumbnails
- User can clear selection before sending
- Files are uploaded to Vercel Blob on send
- Image URLs are included in chat API request as file parts
- Chat API can process messages with image parts
- All code compiles without TypeScript errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-style-extraction/03-01-SUMMARY.md`
</output>
